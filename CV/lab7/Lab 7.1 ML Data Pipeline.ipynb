{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3AOdyMFleXy"
   },
   "source": [
    "# Setting up a Scalable ML Data Pipeline\n",
    "\n",
    "As we have seen, in deep learning we often deal with large datasets, which might even exceed the memory available to us.  \n",
    "\n",
    "In this lab you will learn how to set up a more scalable data pipeline where the data stays on disk until is needed during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNsiAypqPoJT"
   },
   "source": [
    "Once again here is the code to download the Intel Image Classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-hj83CdlkiT",
    "outputId": "079a92ea-d476-4d6a-b98f-ee25d364eb20"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('seg_train'):\n",
    "  !wget -O archive.zip https://www.dropbox.com/scl/fi/ribf92om67kpi34wukl7q/archive.zip?rlkey=qn5v9cwvaqwba8jhsr7diyxnm&dl=1\n",
    "  !unzip -qq archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkqOLAfFleX0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Et6Ct2kaSQrf"
   },
   "source": [
    "This time we will use the Keras function `image_dataset_from_directory`.  It expects the images to be stored in separate directories according to their labels:\n",
    "\n",
    "```\n",
    "   dog/\n",
    "       - dog1.jpg\n",
    "       - dog2.jpg\n",
    "       - ...\n",
    "   cat/\n",
    "       - cat1.jpg\n",
    "       - cat2.jpg\n",
    "       - ...\n",
    "```\n",
    "\n",
    "It returns a Tensorflow `Dataset` object.  Note that it does not load the images from disk -- it just looks the directory and catalogs which images are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4UqkbOvSAOv",
    "outputId": "369330f6-2aec-4725-d57f-3439964a6949"
   },
   "outputs": [],
   "source": [
    "train_ds = keras.preprocessing.image_dataset_from_directory('seg_train/seg_train')\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMQd6L1QTpPE",
    "outputId": "1aa7e7d7-9cf3-474c-f504-25e8d91f097b"
   },
   "outputs": [],
   "source": [
    "train_ds.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQ0P1wTuS9lY"
   },
   "source": [
    "When we iterate over the dataset, it loads batches of images from disk.  The batch size is set by the `batch_size` argument to `image_dataset_from_directory`.\n",
    "\n",
    "Here `.take(1)` tells the dataset we only want the first batch.\n",
    "\n",
    "Because the data is returned as `EagerTensor`s, we have to call `.numpy()` for them to be actually loaded and converted to Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "WP4bSK6pTfR8",
    "outputId": "cbc78f1b-5557-4d0d-8793-688e6f0f49ad"
   },
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "  print('images:',images.shape,images.dtype,'labels:',labels.shape,labels.dtype)\n",
    "  print('image data range:',images[0].numpy().min(),images[0].numpy().max())\n",
    "  plt.imshow(images[0].numpy().astype('uint8'))\n",
    "  plt.title(labels[0].numpy())\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cd0Bk2C7VhSS"
   },
   "source": [
    "`image_dataset_from_directory` resizes the images so that they all have the same shape.  You can control the image size through the `image_size` argument.  The default is $256\\times256$.\n",
    "\n",
    "If the original image is not square, then the image will be somewhat squashed by the resize operation.  To avoid this, you can set `crop_to_aspect_ratio=True` so that it will center crop the image before resizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGN3xf3BXNe1"
   },
   "source": [
    "`image_dataset_from_directory` can automatically create a validation split for you, using the `validation_split` argument.  You need to call the function twice: once with `subset='train'` and once with `subset='validation'` to make both datasets.  And, you should set the `seed` argument to ensure that the same split is used both times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqD-P6WcXn7-",
    "outputId": "bfcff740-d5c3-4a5c-b42d-c8c5302350ba"
   },
   "outputs": [],
   "source": [
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    'seg_train/seg_train',\n",
    "    subset='training',\n",
    "    validation_split=0.1,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pbi9uMqQXxab",
    "outputId": "6fccf327-d7f0-49fe-fb48-58ab0d920f2c"
   },
   "outputs": [],
   "source": [
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    'seg_train/seg_train',\n",
    "    subset='validation',\n",
    "    validation_split=0.1,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fQSBlZdleX1"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Try using `image_dataset_from_directory` in your CNN training.\n",
    "\n",
    "1. First, create the train, val, and test datasets using `image_dataset_from_directory`.\n",
    "\n",
    "Set the image size to 128x128 with center cropping, and use a validation split of 0.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTQjnyL4W-Ci",
    "outputId": "a4d1caab-33bb-48c4-b775-4da2e942ca6e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4K5KZD-0YMrP"
   },
   "source": [
    "2. Set up a CNN for image classification.  We can use a bigger CNN than last time now that we are not using up all that memory to store the dataset.\n",
    "\n",
    "Here's my suggested architecture:\n",
    "\n",
    "* Input layer\n",
    "* 2D convolution, 3x3 kernel, 32 channels, ReLU activation\n",
    "* Max pooling: 2x2 kernel, stride of 2\n",
    "* 2D convolution, 3x3 kernel, 64 channels, ReLU activation\n",
    "* Max pooling: 2x2 kernel, stride of 2\n",
    "* 2D convolution, 3x3 kernel, 128 channels, ReLU activation\n",
    "* Max pooling: 2x2 kernel, stride of 2\n",
    "* 2D convolution, 3x3 kernel, 256 channels, ReLU activation\n",
    "* Max pooling: 2x2 kernel, stride of 2\n",
    "* 2D convolution, 3x3 kernel, 512 channels, ReLU activation\n",
    "* Max pooling: 2x2 kernel, stride of 2\n",
    "* Flatten\n",
    "* Dense output layer configured for multi-class classification\n",
    "\n",
    "However, we are missing something -- the data preprocessing!  Right now the images are on [0 255] range which is not ideal for NN training.\n",
    "\n",
    "To address this, we can add a `Lambda` layer right after the `Input` layer.  It should look like this:\n",
    "\n",
    "`Lambda(lambda x:x/128-1)`\n",
    "\n",
    "The will preprocess the images so to be on [-1 1] range on-the-fly, as the data is processed in the network.\n",
    "\n",
    "Try it out and see what accuracy you can get!  (I reached 82.6% test accuracy with this one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5-a--P5fCu7"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Lambda\n",
    "from keras.regularizers import L2"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
